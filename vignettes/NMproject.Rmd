---
title: "NMproject"
author: "Tarj Sahota"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{NMproject}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Why NMproject?

NMproject's initial outing (the alpha interface) was developed in AZ and internally had 83% voluntary user retention ("user" = someone with 5+ separate model development workflows).  NMproject's main objective is industrialisation via script based model development.

The beta interface is a completely new syntax that address several shortcoming of the previous syntax and expands functionality.

So why NMproject?

- Go from code library templates (shiny interface) to a working parent NONMEM model quickly and entirely within R.  See demo.

- Use R functions and tracked manual editing to create NONMEM runs.  NMproject is the only NONMEM interface (that I know of) that tracks manual edits to NONMEM code in the form of reusable patches.  It is also the only R package (that I know of) with a vectorized model object allowing single runs to be handled in the same way as groups of runs.

- Create end-to-end model development workflows entirely within R without any additional effort. Run caching encourages you to re-execute scripts and rebuild objects frequently to ensure your workflow contains no reproduciblity breaks.  Use workflows to pre-program analyses for project decision points, and repeat workflows to greatly accelerate re-analysis with updated datasets.

- See impactful oncology example where the commitment to pre-program in NMproject and deliver analysis in stats-like timelines got us onto formal go-nogo: https://youtu.be/QVw28Im3Zz0)

- R markdown friendly. Pipe friendly. Create human readable model development logs for other people (or even yourself in 6 months) to read/refresh.

Prerequisites: NMproject targetted towards mid to upper level R/NONMEM users. If you know what a pipe is, what knitr is, you should be good.  If you know dplyr you'll be able to use the advanced functionality to complex workflows


```{r setup, include=FALSE}
library(knitr)
library(NMproject)
library(dplyr)
extdata_path <- system.file("extdata", package = "NMproject")

testfilesloc <- file.path(extdata_path, "theopp")
zip_file <- file.path(extdata_path, "theopp.zip")

files_to_unzip <- unzip(zip_file, list = TRUE)

unzip(zip_file)

dir(all.files = TRUE)
extracted_folders <- dir("theopp", full.names = TRUE)

for(extracted_folder in extracted_folders){
  file.copy(extracted_folder, ".", recursive = TRUE)
}

file.rename("cache", ".cache")
dir(all.files = TRUE)

copied_folders <- basename(gsub("cache", ".cache", extracted_folders))

unlink("theopp", recursive = TRUE)

orig_dir <- getwd()

```


## Demo

The easiest way to familiarise your with NMproject is to follow through the demo.

<iframe width="560" height="315" src="https://www.youtube.com/embed/nAkcEFz0RLg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

First create a new tidyproject (`FILE` -> `New Project` -> `New Directory` -> `New tidyproject`). You'll see a clean analysis directory with empty subfolders.  Run the following in the new R session:

```{r eval = FALSE}
library(NMproject)
setup_nm_demo()
```

This will population the `Scripts` directory with scripts, and deposit the Theopp dataset into the `SourceData` subdirectory.

The scripts are numbered s01.....Rmd, s02....Rmd etc., and are designed to be read and run in order.  This is the best way to familiarize yourself.  The scripts can also be used as template for your own model development

## NMproject Usage

### Creating new R markdowns

There is nothing mandating the use of R markdown in NMproject.  You can use scripts.  However R markdown documents produce nice sharable model development logs which provide a readable description of what steps were performed and in what order.

It is advisable to always start from a template.  Templates can be accessed in `New Rmarkdown` -> `From Template`.  One example template is `model generic` which can be used to get started with our dataset cleaning and exploratory plotting.

### Data cleaning

Your first script in performing an analysis will probably be a dataset assembly or dataset cleaning.  The intent of the `SourceData` directory is to serve as an entry point of raw or externally produced dataset into your analysis directory.

It is *best practice* to use relative paths in your code where possible and to avoid using `setwd()` commands to change the working directory.  E.g. to read a data set in the `SourceData` directory, use `read.csv("SourceData/data.csv")`.

The `write_derived_data()` function can be used to save the NONMEM ready dataset into the `DerivedData` directory:

```{r eval = FALSE}

d %>% write_derived_data("DerivedData/data.csv")

```

See the demo for how/why to create bootstrapped datasets before beginning model development.

### Model development

`New Rmarkdown` -> `From Template` -> `Model development` will get you started with a model development log file.

It's always best to start with NONMEM template too.  Search the code library and bring into staging area of analysis project using the `code_library` addin:

One of the templates is `Models/ADVAN2.mod`.  Select it, `preview()` it and then `stage()` by clicking the buttons and then closing the app.

<iframe width="560" height="315" src="https://www.youtube.com/embed/nTixZB9tfgk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

The model will be in the staging area: `staging/Models/ADVAN2.mod`, not `Models/ADVAN2.mod`.  Files in the staging area are not to be modified. It's similar to the `SourceData` directory in that sense.  This is to ensure that we can make changes to `ADVAN2.mod` in the code library without breaking old analyses that depended on it.

The other important component to understand is that control files are only written to the `Models` subdirectory just before running nonmem via the `run_nm()` command.  Prior to this, control file information is stored within the object itself.

Let's create our first NONMEM object with `new_nm()`.  This will be a parent run to all other runs and thus requires more set up than other runs. Subsequent child objects will inherits characteristics of the parent.

Three arguments are required to create the parent, a run identifier, `run_id`, a control file it's based on, `based_on`, and a (relative) dataset path `data_path`:

```{r include=FALSE}

ls_code_library("Models/ADVAN2.mod") %>%
  stage()

```


```{r}

m1 <- new_nm(run_id = "m1",
             based_on = "staging/Models/ADVAN2.mod",
             data_path = "DerivedData/data.csv")

m1

```

Display the object by typing `m1` in the console.  Notice that the `run_in` field is point to `Models`.  This can be changed by piping the function of the same name e.g. 

```{r}

m1 <- new_nm(run_id = "m1",
             based_on = "staging/Models/ADVAN2.mod",
             data_path = "DerivedData/data.csv") %>%
  run_in("NONMEM/base_model")

```

will run all models in a subdirectory of a subdirectory `NONMEM/base_model` instead.  Any field can by modified using a similar heuristic.

To extract a field (rather than set a field) use the same function without additional arguments:

```{r}

m1 %>% run_in()

```

For now though, lets stay with the default `run_in` location.  

*NOTE:* the field `ctl_name` refers to the name of the control that will be created.  This will only be created when it the model is run with the `run_nm()` function (described later).  For now, the control file contents reside inside the object.  To view these you can use `show_ctl(m1)`, or `text(m1)`.

A few automatic edits from the staged control file and a compact representation of these changes can be shown by highlighting the above code and selecting the `nm_diff` addin which show what has been changed.

<iframe width="560" height="315" src="https://www.youtube.com/embed/mYUaKrj0-YE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Learning how to read to diffs will be an important skill in NMproject you will pick up over time.  Notice how the `$DATA` has been updated to refer to the new location.

The default `cmd()` field of the object is `execute {ctl_name} -dir={run_dir}`.  The braces are referred to as `glue` fields using the `glue` package.  These refer to field names of the object that will be substituted in.  For completeness on the next step we will explicitly set this to ensure our model development is easy to read.

```{r eval=FALSE}

m1 <- new_nm(run_id = "m1",
             based_on = "staging/Models/ADVAN2.mod",
             data_path = "DerivedData/data.csv") %>%
  cmd("execute {ctl_name} -dir={run_dir}")

```

The final steps to gets the NONMEM model ready is to fill in the remaining blanks in the template.  They are the `$INPUT` and `$THETA`, `$OMEGA`.  For this we will use the `fill_input()` and `init_theta()` and `init_omega()` before piping into our `run_nm()` command.

```{r eval=FALSE}

m1 <- new_nm(run_id = "m1",
             based_on = "staging/Models/ADVAN2.mod",
             data_path = "DerivedData/data.csv") %>%
  cmd("execute {ctl_name} -dir={run_dir}") %>%
  fill_input() %>%
  init_theta(init = c(-2, 0.5, 1)) %>%
  init_sigma(init = c(0.1, 0.1)) %>%
  run_nm()

```

### Fast NMTRAN checks

In a cluster environment it is especially important to be able to diagnose data and control file issues before sending jobs off to the grid.  Otherwise, you often need to wait minutes for errors that can be spotted immediately.  It's therefore highly recommended to make use of the `nm_tran` addin.  This will only run NMTRAN checks to find control file syntax errors and dataset errors.  It will not run nonmem itself.  To use this addin, highlight the above code and select the `nm_tran` addin near the top of the RStudio GUI.

### Manual edits

Often there will not be the functions to do the control file manipulation you want.  Although it is preferable to stick to automatic control file manipulation functions, you can do full tracked `manual_edit`s via the addin menu.  Again, just highlight the code, click the addin and follow the instructions:

<iframe width="560" height="315" src="https://www.youtube.com/embed/HyCHeAAiwy4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Shiny run monitor

To view all runs in the workspace and track progress:

```{r eval=FALSE}
shiny_nm()
```

To do basic goodness of fit open the post processing Rmarkdown template, follow instructions, customise your template save it (e.g. as `Scripts/basic_gof.Rmd`) and run in your log script with

```{r eval=FALSE}
m1 <- m1 %>% nm_render("Scripts/basic_gof.Rmd")
```

It will create the output in `Results` (or results_dir(m1))

If we already have a parent run `m1` using `ADVAN2 TRANS1`, we can create a `child()` run that uses `TRANS2` using `subroutine()`:

```{r include=FALSE}

m1 <- dir(".cache", full.names = TRUE) %>%
  subset(grepl("m1$",.)) %>%
  {as_nm_list(readRDS(.)$object)}

m2 <- dir(".cache", full.names = TRUE) %>%
  subset(grepl("m2$",.)) %>%
  {as_nm_list(readRDS(.)$object)}

m2WT <- dir(".cache", full.names = TRUE) %>%
  subset(grepl("m2WT$",.)) %>%
  {as_nm_list(readRDS(.)$object)}

m1orig <- m1

## need to skip overwrite because new user will mean directory gets overwriten
overwrite_behaviour("skip") 

```

```{r eval=FALSE}

m2 <- m1 %>% child() %>%
  subroutine(trans = 2) %>% 
  run_nm()

```

View exactly what's been changed by highlighting the above code in RStudio and clicking the `nm_diff` addin to see what's been changed before running.  Here, changes will be in the `$SUB`, `$PK` and `$THETA`.

To add a covariate using PsN coding conventions use `add_cov()`:

```{r eval=FALSE}

m2WT <- m2 %>% child(run_id = "m2WT") %>%
  add_cov(param = "CL", cov = "WT", state = "linear") %>%
  run_nm()

```

Apply a fully editable goodness of fit R markdown template to both runs `m2` and `m3`:

```{r eval=FALSE}

c(m2, m3) %>% nm_render("Scripts/basic_gof.Rmd")
## will produce two run specific html reports in the "Results" directory for run evaluation

```

`c(m1, m3)` is a vector object of 2 NONMEM runs.  It can be embedded into data.frames/tibbles.  

Evaluate and compare runs on the fly with the following commands

```{r}
rr(c(m2, m2WT))
plot_iter(m2, skip = 10) ## skip first 10 interations 
covariance_plot(m2)
```

However these are better placed inside templates to enable rapid and consistent re-use.

Create a simulation run using `update_parameters()` and `convert_to_simulation()`.  Apply vpc and ppc diagnostics
  
```{r eval=FALSE}
m2s <- m2 %>% child(run_id = "m2s") %>%
              update_parameters(m2) %>%
              convert_to_simulation(subpr = 50) %>%
              run_nm()

m2s %>% nm_render("Scripts/basic_vpc.Rmd")
m2s %>% nm_render("Scripts/basic_ppc.Rmd")

```

Don't forget to comment your code with your decision making.

### Clean up runs

```{r eval=FALSE}

m1 %>% ls_tempfiles() ## will list all temporary files associate with run m1

## remove all temporary files associated with m1
m1 %>% ls_tempfiles() %>% unlink()

## Not specifying an argument will list temporary files of all runs
ls_tempfiles()

```

### Running NONMEM in parallel

Two fields `parafile` and `cores` when combined with a suitable `cmd` can enable runs to be executed in parallel using PsN.

```{r eval=FALSE}
m1 <- new_nm(run_id = "m1",
             based_on = "staging/Models/ADVAN2.mod",
             data_path = "DerivedData/data.csv") %>%
  cmd("execute {ctl_name} -parafile={parafile} -dir={run_dir} -nodes={cores}") %>%
  parafile("/opt/NONMEM/nm750/run/mpilinux8.pnm") %>%
  cores(4) %>%
  run_nm()

```

```{r include = FALSE}
m1 <- m1 %>%
  cmd("execute {ctl_name} -parafile={parafile} -dir={run_dir} -nodes={cores}") %>%
  parafile("/opt/NONMEM/nm750/run/mpilinux8.pnm") %>%
  cores(4)
```

*ADVANCED* You can make use of the vectorized objects to run multiple levels of parallelisation to invest which is the best for your particular model.  Here is sample code for that uses `m1` as a parent

```{r}
dc <- tibble(cores = c(1, 3, 10, 30)) %>%
  mutate(m = m1 %>% 
           child(run_id = cores) %>%
           cores(cores) %>%
           run_in("Models/m1_coretest"))

dc

dc$m %>% cmd()

# dc$m %>% run_nm()  ## command to run

```


### Bootstraps

The package `rsample` can be used to create bootstrap datasets in your initial data manipulation scripts.  The following is an example bootstrap dataset being prepared with stratification on `SEX` and bodyweight `WTC` categorised in two categories  

```{r eval = FALSE}

d <- d %>%
  mutate(WT_C = cut(WT, breaks = 2, labels = FALSE),
         STRATA = paste(SEX, WT_C, sep = "_"))

d_id <- d %>% distinct(ID, STRATA)

set.seed(123)

## create large set of resamples (to enable simulation to grow without ruining seed)
bootsplits <- rsample::bootstraps(d_id, 100, strata = "STRATA")

dir.create("DerivedData", showWarnings = FALSE)
bootsplits %>% saveRDS("DerivedData/bootsplit_data.csv.RData")

```

In a model development script, the following, performs a 100 sample bootstrap of model `m1`

```{r eval=FALSE}

m1_boot <- m1 %>% make_boot_datasets(samples = 100, overwrite = TRUE)

m1_boot$m <- m1_boot$m %>% run_nm()

m1_boot$m %>% nm_list_render("Scripts/basic_boot.Rmd")

```

Results can be viewed in `Results/basic_boot.m1.html`.


```{r include=FALSE}
m1 <- dir(".cache", full.names = TRUE) %>%
  subset(grepl("m1$",.)) %>%
  {as_nm_list(readRDS(.)$object)}
```

### Setting initial estimates

The functions `init_theta`, `init_omega` and `init_sigma` can be used to get and set initial estimation, parameter bounds, names, units, etc.  The work much like the functions used to access fields of the nm object

```{r}

## return a tibble version of $OMEGA with init_omega()
io <- m1 %>% init_omega()
io 

```

Note that `io` is a list of a data.frame.  This makes manipulation a bit more difficult, but referring to `io[[1]]` instead `io` will allows you to manipulate io with R's standard data.frame manipulation functions.  There are also built in functions like `block` and `unblock` (to create $OMEGA BLOCKS for correlated random effects).

```{r}

io <- io %>% block(c(2,3))  ## make block out ETA 2 and 3

## put modified io wit
m1 <- m1 %>% init_omega(io)
m1 %>% dollar("OMEGA")

```

```{r}

## for demo purposes we'll reverse the process with unblock()
io <- m1 %>% init_omega()
io <- io %>% unblock(c(2,3))
m1 <- m1 %>% init_omega(io)
m1 %>% dollar("OMEGA")

```

### Perturbing initial parameters

To modify initial estimates, we'll use the `mutate`-like behaviour of `init_*` functions.  We will modify the `init` by referencing itself.  We'll modified all our fixed effects (log transformed) by 30%

```{r include=FALSE}
m1 <- dir(".cache", full.names = TRUE) %>%
  subset(grepl("m1$",.)) %>%
  {as_nm_list(readRDS(.)$object)}
```

```{r eval=FALSE}

#m1 <- m1 %>% init_theta(init = rnorm(init, mean = init, sd = 0.3))
# m1 %>% dollar("THETA")  ## view with this

```

As a more advanced exercise, lets create 5 runs with modified initial estimates by combining the above with `dplyr::mutate()`.  The basic idea is to contruct a `tibble` (if you are unfamiliar with `tibble`s, they are a tidyverse expansion of the concept of a `data.frame`), and then use a `dplyr::mutate` statement to construct a column vector of nm objects.  Below the column vector is produced by starting with the parent object `m1` and then supplying a vector rather than a scalar to the `child()` function.  Since the `rep` column is length 5, this will make the nm_object length 5.

```{r eval = FALSE}

dp <- tibble(rep = 1:5) %>%
  mutate(
    m = m1 %>% ## start with single parent run, m1, an nm object of length 1
      child(run_id = rep) %>% ## rep is vector of length 5
      ## this makes the child() output a nm object vector of length 5 - each
      ## with a unique run_id do the same manipulation above - since NMproject
      ## functions are vectorized, this will apply the same manipulation
      ## elementwise
      init_theta(init = rnorm(init, mean = init, sd = 0.3))
  )

length(m1)
length(dp$m)

## the m column of dp is a nm object vector, display all $THETAs like this
dp$m %>% dollar("THETA")

## run all runs in dp$m with the normal syntax 
# dp$m %>% run_nm()

```

### Automating model checking

We'll use a similar combination of nm object vectorized and `dplyr` the previous section to test multiple model structures in one go using the `subroutine()` control file manipulation function.  `.available_advans` shows all available advans.


```{r eval=FALSE}

.available_advans ## display available advans

dt <- .available_advans %>%
  ## filter only for oral dosing advans
  filter(oral %in% TRUE) %>%
  ## mutate state create a column vector m of nm objects
  ## first step is to create children runs from the parent object m1
  ## this is done by supplying a vector of run_ids to the child() function
  mutate(m = m1 %>% ## start with parent m1 again
           child(run_id = label) %>% ## create multiple children using "label" column
           ## then use advan and trans columns with subroutine()
           subroutine(advan = advan, trans = trans))

## view the $PK blocks of each
dt$m %>% dollar("PK")

## run them all and wait for them to finish
dt$m %>% run_nm() %>% wait_finish()

summary_wide(dt$m)

#dt$m %>% 
#  subset(ofv(.) < 120) %>%
#  nm_render("Scripts/basic_gof.Rmd")


```

### Parallel efficiency test

Often you'll want to know the right level of parallelisation to run your model to maximise speed without wasting too many resources.  The following uses the vectorized nm objects in a similar way with `dplyr::mutate()` to create multiple runes with different levels of parallelisation. For the demo we'll just test it across 1, 2 and 3 cores, but this can be an arbitrary vector.

```{r eval = FALSE}

dc <- tibble::tibble(cores = c(1, 2, 3)) %>%  ## only 3 different values to test for demo purposes
  mutate(m = m1 %>% ## start with parent m1 again
           ## supply the "cores" vector (of the tibble) to child(), this will create 3 runs
           child(run_id = cores) %>%
           ## run them all in m1_coretest
           run_in("Models/m1_coretest") %>%
           ## run them all with the following execute command
           cmd("execute {ctl_name} -parafile={parafile} -dir={run_dir} -nodes={cores}") %>%
           ## and the following parafile
           parafile("/opt/NONMEM/nm75/run/mpilinux8.pnm") %>%
           ## and finally set the cores to the "cores" vector
           cores(cores))

```

```{r eval = FALSE}

## run them all and wait for them to finish
dc$m %>% run_nm() %>% wait_finish()

## following is disabled for the demo
# job_info(dc$m)

## plot cores vs Rtime or Ttime to get plots of run time and total time vs number of CPUs

# ggplot(aes(x = cores, y = Rtime)) + theme_bw() +
#   geom_point()

```

### Simulation re-estimation

You can also use the vectorized nature to create a simulation re-estimation routines from scratch.

Whenever making a routine that will scale up to 100s or 1000s or runs, always start with 1 or 2 replicates.  Get the code working below, and then rerun with desired number of replicates (here we're just using 3 for demo purposes).  You will not waste time because `run_nm()` will skip over runs that have already completed. 

```{r eval=FALSE}

n_sims <- 3  ## start small, scale up later

dsr <- tibble(sim = 1:n_sims) %>%
  mutate(
    msim = m1 %>%              ## start with single parent run, m1, an nm object of length 1
      update_parameters() %>%  ## update inits to finals, here nm object is still length 1
      child(run_id = sim, parent = m1) %>%  ## at this point it becomes length n_sims
      run_in("Models/m1_simest") %>% ## this applies the run_in modification to all n_sims runs
      convert_to_simulation(subpr = 1, seed = sim) ## converts all to simulation
  )

## run, wait, read results and then write to run_dir paths of simulations
dsr$msim %>% run_nm() %>% 
  wait_finish() %>%
  output_table(only_append = "DV_OUT") %>%
  write_derived_data(file.path(run_dir_path(dsr$msim), "simdata.csv"))

## Now create mest column
dsr <- dsr %>%
  mutate(
    mest = m1 %>% child(run_id = sim) %>%  ## estimations derived from m1
      run_in("Models/m1_simest/est") %>%   ## run in a new subdirectory
      data_path(file.path(run_dir_path(msim), "simdata.csv")) %>%    ## set new data_paths
      ## refill $INPUT. Rename DV to be DV_OUT column. Run nm_diff() command below to see
      ## what has changed
      fill_input(rename = list("DV_OBS" = "DV", "DV" = "DV_OUT"))
  )

# nm_diff(dsr$mest[1])

dsr$mest %>% run_nm() %>% 
  wait_finish() %>%
  summary_wide(parameters = "all")

```



## FAQ

### + After having closed my session how to I recreate my workspace

Just re-run all the code again.

If nothing has changed with regards to datasets and control files run_nm() will retrieve cached results without running nonmem.


### + I see the PMX code library has been updated, how can I update my local version of it?

The PMX code library is version controlled with `git`.  Ensure you have git installed, navigate to the local PMX code library repository and type `git pull`.  Git will complain if you have made changes to your local directory since downloading it.  If you have, you need to `commit` those changes before using `git pull`.  See git help for more information on how to do this.  Consider splitting your code library into multiple repositories for easier management (e.g. one public, one for your organisation, one for you)

### + We already have directory of R/NONMEM scripts/templates, how can we also use these?

Append your directory location to the `code_library_path` option.  To do this add the following command to your `~/.Rprofile` (or `$R_HOME/etc/Rprofile.site`) configuration file:

```{r eval=FALSE}
options(code_library_path = c("/path/to/PMXcodelibrary/",
                              "path/to/existing/repository"))
```

### + How can I contribute to the PMX code library?

Log in to github (create an account if necessary).  Fork the repository `tsahota/PMXcodelibrary`. Make your change.  Create a pull request detailing your change.

### + How do I run this on SGE?

There is a pre-prepared built in `sge_parallel_execute` character object that's part of NMproject.  This uses the grid functionality built into PsN and has been tested to work within the Metworx platform.  Simply type it in the console to see the contents.  Required fields are `parafile`, `cores`.  Ensure these are set for your parent object like so.

```{r eval=FALSE}
m1 <- m1 %>% 
  cmd(sge_parallel_execute) %>%
  parafile("/opt/NONMEM/nm75/run/mpilinux8.pnm") %>%
  cores(8) %>%
  run_nm()
```

Note that child object will inherit the same `cmd` structure, `cores` and `parafile`.

### + How do I run this on other clusters like Slurm, LSF, Torque

The workflow is similar to above where PsN handles the grid submission. You will need to create your own analog character to `sge_parallel_execute` for your respective cluster.  It is recommended to consult PsN documentation to "gridify" your PsN command.  Once you have this, it's just a simple matter of replacing your control file name, run directory, parafile and desired number of cores with the relevant glue field (e.g. `{parafile}`) and then putting it into your parent `cmd()` command to get it running through NMproject.

Feel free to contact me if you need help

### + How do I run NONMEM via a PsN/NONMEM docker container

This requires setting `cmd()` field of the first (parent) nm object and also setting `nm_tran_command()` once in your script.

Easiest way to understand this is via an example: The following assumes the docker container has been set as shown in the fabulous `https://github.com/billdenney/Pharmacometrics-Docker` repository:

Set cmd for an `execute` command like so:

```{r eval=FALSE}
m1 %>% 
  cmd("docker run --rm --user=$(id -u):$(id -g) -v $(pwd):/data -w /data humanpredictions/psn execute {ctl_name} -dir={run_dir}")
```

`run_nm()` will then execute NONMEM via the docker container.  All subsequent child objects will inherit the same command structure.  Note the use the glueing object fields `ctl_name` and `run_dir` so child objects can inherit the same command structure to save the command being rewritten for each run)

Set up dockerized NMTRAN checking with:

```{r eval=FALSE}
nm_tran_command("docker run --rm --user=$(id -u):$(id -g) -v $(pwd):/data -w /data humanpredictions/psn /bin/bash -c '/opt/NONMEM/nm_current/tr/NMTRAN.exe < {ctl_name}'")
```


### + My Rstudio Server is on a different linux server to my NONMEM cluster.  How can I set up NMproject to work with this?

You need to ensure your account has passwordless ssh set up.  Then create a `system_nm()` option in your `~/.Rprofile` configuration file which appends an ssh statement to the system call e.g. the following will set you up to connect to the host `clustername`:

```{r eval=FALSE}
options(system_nm=function(cmd,...) {
        system(paste0("ssh -q clustername \"cd $(pwd); ",cmd,"\""),...)
})
```

### + I'm working on a windows laptop but want to use my NONMEM cluster for NONMEM jobs.  How can I set up NMproject to work with this?

This is not recommended as it requires R working directory being set to a networked drive.  This is very slow.  If you really want to though consider modifying the `system_nm()` option, as in the above FAQ question, to use `plink` to ssh to the server, change to the relevant working directory and submit a command.  This has not been tested however and results are likely to be disappointing.

### + My organisation has a different control file convention to the runXX.mod convention.  Can I change this?

Yes, you can specify the convention with the ctl_path() on your parent object e.g. to change the convention to nm.XX.con

```{r eval=FALSE}
m %>% ctl_path("Models/nm.{run_id}.com")
```

### + How do I submit a command directly to the NONMEM server?

```{r eval=FALSE}
system_nm("command_to_run", dir="path/to/dir")
```

### + There is functionality in PsN's runrecord, sumo or Pirana that I would like but is not currently available in NMproject.

NMproject doesn't change PsN's default directory structure, everything in the "Models" directory is as if you lauched the jobs from the command line.  Therefore you can continue to use PsN functions on the command line.  You can also continue using Pirana by pointing it towards your models directory.

If it's something you think really should be part of NMproject, open a github "issue" and ask for the feature.

### + I don't want to use NMproject on my analysis project any more, can I go back to submitting runs on the command line

Yes, NMproject doesn't change PsN's default directory structure, so you can go back to running PsN via command line.  If there a bug or a feature you think really should be part of NMproject, consider opening a github "issue" and asking.

### + I work for a CRO. My client doesn't have NMproject, how can send the analysis to them.

NMproject doesn't change PsN's default directory structure, and everything will work for them as long as their version of R (and package versions) are compatible.  It is recommended to run Renvironment_info() as a last step before sending the analysis directory so they can see the package versions you used.

Obviously they will not be able to run code that is dependent on NMproject unless they install it.  But your model development script can still serve as a helpful, human readable process description of your model development steps.


```{r include=FALSE}
## clean up 
getwd()
unlink(copied_folders, recursive = TRUE)
dir(all.files = TRUE)
```

